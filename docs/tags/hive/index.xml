<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>hive on Fatkun&#39;s Blog</title>
    <link>https://fatkun.github.io/tags/hive/</link>
    <description>Recent content in hive on Fatkun&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 09 Nov 2017 06:10:06 +0000</lastBuildDate>
    
	<atom:link href="https://fatkun.github.io/tags/hive/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>HIVE-13936 Hive windowing function 导致 reduce OOM</title>
      <link>https://fatkun.github.io/2017/11/hive-windowing-function-lead-reduce-oom.html</link>
      <pubDate>Thu, 09 Nov 2017 06:10:06 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2017/11/hive-windowing-function-lead-reduce-oom.html</guid>
      <description>这个是row_number https://issues.apache.org/jira/browse/HIVE-13936 http://grokbase.com/t/hive/user/148m45m9ge/help-needed-out-of-memory-with-windowing-functions</description>
    </item>
    
    <item>
      <title>[BUG]HIVE-9613 left join会导致数据错位</title>
      <link>https://fatkun.github.io/2017/07/bughive-9613-left-join%E4%BC%9A%E5%AF%BC%E8%87%B4%E6%95%B0%E6%8D%AE%E9%94%99%E4%BD%8D.html</link>
      <pubDate>Fri, 07 Jul 2017 10:32:00 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2017/07/bughive-9613-left-join%E4%BC%9A%E5%AF%BC%E8%87%B4%E6%95%B0%E6%8D%AE%E9%94%99%E4%BD%8D.html</guid>
      <description>category city rank src_category_en src_city_name_en jinrongfuwu shanghai 1 danbaobaoxiantouzi sh ktvjiuba shanghai 2 zpwentiyingshi sh but int hive0.14,the results in the column **src\_category\_en** is wrong,and is just the **city** contents: category city rank src_category_en src_city_name_en jinrongfuwu shanghai 1 shanghai sh ktvjiuba shanghai 2 shanghai sh</description>
    </item>
    
    <item>
      <title>Hive遇到问题汇总</title>
      <link>https://fatkun.github.io/2017/06/hive%E9%81%87%E5%88%B0%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB.html</link>
      <pubDate>Fri, 16 Jun 2017 05:39:56 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2017/06/hive%E9%81%87%E5%88%B0%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB.html</guid>
      <description>新增两个字段，但查出来的值为null。 分区有自己的字段信息，检查分区的字段信息是否和表的不一致。 desc table_name parttion (pt=’2016-01-01′); S</description>
    </item>
    
    <item>
      <title>Hive On Tez cloudera5.4</title>
      <link>https://fatkun.github.io/2017/05/hive-on-tez-cloudera5-4.html</link>
      <pubDate>Mon, 01 May 2017 10:52:17 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2017/05/hive-on-tez-cloudera5-4.html</guid>
      <description>配置 tez-site.xml &amp;lt;configuration&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;tez.lib.uris&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;${fs.defaultFS}/apps/tez-0.8.5/,${fs.defaultFS}/apps/tez-0.8.5/lib/&amp;lt;/value&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;tez.use.cluster.hadoop-libs&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;tez.runtime.compress&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;property&amp;gt; &amp;lt;name&amp;gt;tez.runtime.compress.codec&amp;lt;/name&amp;gt; &amp;lt;value&amp;gt;org.apache.hadoop.io.compress.SnappyCodec&amp;lt;/value&amp;gt; &amp;lt;/property&amp;gt; &amp;lt;/configuration&amp;gt; 调优参数 tez.grouping.min-size 分片最小限制 报错处理 找不到lzo Caused by: java.lang.ClassNotFoundException: Class com.hadoop.compression.lzo.LzoCodec not found at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2018) at org.apache.hadoop.io.compress.CompressionCodecFactory.getCodecClasses(CompressionCodecFactory.java:128) ... 23 more LZO包没加载到，我是把lz</description>
    </item>
    
    <item>
      <title>hive merge小文件</title>
      <link>https://fatkun.github.io/2016/11/hive-merge%E5%B0%8F%E6%96%87%E4%BB%B6.html</link>
      <pubDate>Mon, 21 Nov 2016 10:47:17 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2016/11/hive-merge%E5%B0%8F%E6%96%87%E4%BB%B6.html</guid>
      <description>2.输出合并 set hive.merge.mapfiles = true #在Map-only的任务结束时合并小文件（默认开启） set hive.merge.mapredfiles = true #在Map-Reduce的任务结束时合并小文件 set hive.merge.size.per.task = 256*1000*1000 #合</description>
    </item>
    
    <item>
      <title>HIVE-10815 随机选择HiveMetaStoreClient</title>
      <link>https://fatkun.github.io/2016/10/hive-10815-%E9%9A%8F%E6%9C%BA%E9%80%89%E6%8B%A9hivemetastoreclient.html</link>
      <pubDate>Sat, 22 Oct 2016 03:04:03 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2016/10/hive-10815-%E9%9A%8F%E6%9C%BA%E9%80%89%E6%8B%A9hivemetastoreclient.html</guid>
      <description>https://issues.apache.org/jira/browse/HIVE-10815 目前cdh5.4.0版本的hive第一次连接的时候，固定是使用第一个，只有连接失败后，才随机选择。 HiveMetaStoreClient.java // user wants file store based configuration if (conf.getVar(HiveConf.ConfVars.METASTOREURIS) != null) { String metastoreUrisString[] = conf.getVar( HiveConf.ConfVars.METASTOREURIS).split(&#34;,&#34;); metastoreUris =</description>
    </item>
    
    <item>
      <title>hive1.1.0查询和旧版本不一致问题分析</title>
      <link>https://fatkun.github.io/2015/06/hive-join-failed.html</link>
      <pubDate>Sun, 28 Jun 2015 07:08:22 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2015/06/hive-join-failed.html</guid>
      <description>背景 在查询以下语句的时候结果不正确，无法join tab1.tm=tab2.hour。如果存在以下类似的语句，有子查询的group by，外层有</description>
    </item>
    
    <item>
      <title>hive简单查询的过程</title>
      <link>https://fatkun.github.io/2014/08/hive-simple-query.html</link>
      <pubDate>Thu, 21 Aug 2014 06:07:21 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2014/08/hive-simple-query.html</guid>
      <description>查询以下语句的过程 select fr from xxxxxx where substr(fr, 1, 1) = &#39;a&#39;; Hive查询在编译的阶段把语句转换成一个个有层级关系的Operator，然后执行下去。 ExecMapp</description>
    </item>
    
    <item>
      <title>【转】hive 结合执行计划 分析 limit 执行原理</title>
      <link>https://fatkun.github.io/2014/01/hive-limit.html</link>
      <pubDate>Mon, 27 Jan 2014 08:57:05 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2014/01/hive-limit.html</guid>
      <description>这篇文章介绍了limit是怎样执行的，从大体上看代码的运行情况。备忘。 http://yaoyinjie.blog.51cto.com/3189782/923378</description>
    </item>
    
    <item>
      <title>动态注册hive udf</title>
      <link>https://fatkun.github.io/2013/12/register-udf.html</link>
      <pubDate>Sun, 22 Dec 2013 15:07:35 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2013/12/register-udf.html</guid>
      <description>&lt;h2 id=&#34;目标&#34;&gt;目标&lt;/h2&gt;
&lt;p&gt;可以不重启hive服务端动态增加或更新udf，本文用到动态加载以及hive hook实现。&lt;/p&gt;
&lt;h2 id=&#34;看看原来的代码是怎样写的&#34;&gt;看看原来的代码是怎样写的&lt;/h2&gt;
&lt;p&gt;我看的是cdh4.3.0代码，目前有两个地方注册udf，
一个是在org.apache.hadoop.hive.ql.exec.FunctionRegistry类里，大部分的内置udf都是在这里注册的，很多网站都是通过修改这里代码重新打包来注册udf。
第二个是最近新增了一个hive-builtins*.jar文件，注册函数是在&lt;/p&gt;
&lt;pre lang=&#34;java&#34; escaped=&#34;true&#34;&gt;public SessionState(HiveConf conf) {
...
      Class&amp;lt;?&amp;gt; pluginClass = Utilities.getBuiltinUtilsClass();
      URL jarLocation = pluginClass.getProtectionDomain().getCodeSource().getLocation();
      add_builtin_resource(ResourceType.JAR, jarLocation.toString());
      FunctionRegistry.registerFunctionsFromPluginJar(jarLocation, pluginClass.getClassLoader());
...
  }&lt;/pre&gt;
&lt;p&gt;通过找到org.apache.hive.builtins.BuiltinUtils类定位jar的位置，把jar包加入hive.added.jars.path配置里，然后通过FunctionRegistry.registerFunctionsFromPluginJar来注册udf&lt;/p&gt;
&lt;pre lang=&#34;java&#34; escaped=&#34;true&#34;&gt;//我们可以用这两个方法来注册udf
public static void registerTemporaryUDF(String functionName, Class&amp;lt;? extends UDF&amp;gt; UDFClass, boolean isOperator)
public static void registerFunctionsFromPluginJar(URL jarLocation, ClassLoader classLoader)&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>hiveserver2 python client</title>
      <link>https://fatkun.github.io/2013/11/hiveserver2-python-client.html</link>
      <pubDate>Sun, 17 Nov 2013 16:45:11 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2013/11/hiveserver2-python-client.html</guid>
      <description>一个hiveserver2 python客户端的例子，大部分代码来自于hue。 忽略了一些必要的判断，只是做一个简单的例子。 需要安装thrift</description>
    </item>
    
    <item>
      <title>在hive中使用parquet (CDH4.3)</title>
      <link>https://fatkun.github.io/2013/10/hive-use-parquet.html</link>
      <pubDate>Mon, 21 Oct 2013 17:05:47 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2013/10/hive-use-parquet.html</guid>
      <description>hadoop版本 cdh4.3 使用impala创建parquet表后，查询会出错。 [impala:21000] &amp;gt; select * from foo; Query: select * from foo ERROR: AnalysisException: Failed to load metadata for table: default.foo CAUSED BY: TableLoadingException: Failed to load metadata for table: foo CAUSED BY: MetaException: org.apache.hadoop.hive.serde2.SerDeException SerDe</description>
    </item>
    
    <item>
      <title>[备忘]Hive权限授权命令</title>
      <link>https://fatkun.github.io/2013/08/hive-auth.html</link>
      <pubDate>Sun, 25 Aug 2013 08:13:58 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2013/08/hive-auth.html</guid>
      <description>官方文档：https://cwiki.apache.org/confluence/display/Hive/LanguageManual+A</description>
    </item>
    
    <item>
      <title>Hive的Lateral View</title>
      <link>https://fatkun.github.io/2013/06/hive%E7%9A%84lateral-view.html</link>
      <pubDate>Tue, 11 Jun 2013 18:10:14 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2013/06/hive%E7%9A%84lateral-view.html</guid>
      <description>Lateral View用于把UDTF的行转列结果集合在一起提供服务。Lateral View可以返回多列数据，前提是UDTF注册的输出个数。 UDTF代码参</description>
    </item>
    
    <item>
      <title>hive-builtins文件找不到</title>
      <link>https://fatkun.github.io/2013/06/filenotfoundexception-hive-builtins.html</link>
      <pubDate>Tue, 11 Jun 2013 16:57:19 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2013/06/filenotfoundexception-hive-builtins.html</guid>
      <description>java.io.FileNotFoundException: File does not exist: hdfs://localhost:8020/home/fatkun/hive-0.10.0-cdh4.3.0/lib/hive-builtins-0.10.0-cdh4.3.0.jar at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:824) at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:288) at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:224) at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestamps(ClientDistributedCacheManager.java:93) at org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineTimestampsAndCacheVisibilities(ClientDistributedCacheManager.java:57) at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:254) at org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(JobSubmitter.java:290) at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:361) at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1269) at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1266) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408) at org.apache.hadoop.mapreduce.Job.submit(Job.java:1266) at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:606) at org.apache.hadoop.mapred.JobClient$1.run(JobClient.java:601) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:396) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1408) at org.apache.hadoop.mapred.JobClient.submitJobInternal(JobClient.java:601) at org.apache.hadoop.mapred.JobClient.submitJob(JobClient.java:586) at org.apache.hadoop.hive.ql.exec.ExecDriver.execute(ExecDriver.java:448) at org.apache.hadoop.hive.ql.exec.ExecDriver.main(ExecDriver.java:690) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25) at java.lang.reflect.Method.invoke(Method.java:597) at org.apache.hadoop.util.RunJar.main(RunJar.java:208) Job Submission failed with exception</description>
    </item>
    
    <item>
      <title>Hive更改输入输出文件格式</title>
      <link>https://fatkun.github.io/2013/06/alter-table-partition-file-format.html</link>
      <pubDate>Tue, 04 Jun 2013 07:52:01 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2013/06/alter-table-partition-file-format.html</guid>
      <description>文档：https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL</description>
    </item>
    
    <item>
      <title>Hive改表名后查询不了数据(DataNucleus缓存问题)</title>
      <link>https://fatkun.github.io/2013/05/hive-rename.html</link>
      <pubDate>Wed, 29 May 2013 17:21:15 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2013/05/hive-rename.html</guid>
      <description>现象 改了Hive表名后查询不了任何数据。 重现方式 开启两个hive命令行， 先在第一个hive查询一条语句：select * from logs1; 然后在第二个hiv</description>
    </item>
    
    <item>
      <title>Hive – JOIN实现过程</title>
      <link>https://fatkun.github.io/2013/01/hive-join.html</link>
      <pubDate>Sun, 20 Jan 2013 15:12:31 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2013/01/hive-join.html</guid>
      <description>准备数据 语句 SELECT a.uid,a.name,b.age FROM logs a JOIN users b ON (a.uid=b.uid); 我们希望的结果是把users表join进来获取age字段。 hive&amp;gt; select * from logs; OK a 苹果 5 a 橙子 3 b 烧鸡 1 hive&amp;gt; select * from users; OK a</description>
    </item>
    
    <item>
      <title>Hive – Group By 的实现</title>
      <link>https://fatkun.github.io/2013/01/hive-group-by.html</link>
      <pubDate>Sun, 20 Jan 2013 14:53:23 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2013/01/hive-group-by.html</guid>
      <description>准备数据 SELECT uid, sum(count) FROM logs group by uid; hive&amp;gt; select * from logs; a 苹果 5 a 橙子 3 a 苹果 2 b 烧鸡 1 hive&amp;gt; SELECT uid, sum(count) FROM logs group by uid; a 10 b 1 计算过程 默认设置了hive.map.aggr=t</description>
    </item>
    
    <item>
      <title>Hive – Distinct 的实现</title>
      <link>https://fatkun.github.io/2013/01/hive-distinct.html</link>
      <pubDate>Sun, 20 Jan 2013 14:34:13 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2013/01/hive-distinct.html</guid>
      <description>准备数据 语句 select count, count(distinct uid) from logs group by count; hive&amp;gt; select * from logs; OK a 苹果 3 a 橙子 3 a 烧鸡 1 b 烧鸡 3 hive&amp;gt; select count, count(distinct uid) from logs group by count; 1 1 3 2 根据count分组，计算独立用户数。 计</description>
    </item>
    
    <item>
      <title>Hive内容包含有\001会当成分割符</title>
      <link>https://fatkun.github.io/2012/10/hive-seprator.html</link>
      <pubDate>Sun, 21 Oct 2012 14:45:54 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2012/10/hive-seprator.html</guid>
      <description>起因 发现某一行一列数据多了一个\001字符，导致select的时候在这一列后面的结果都不正确。 重现 hive版本：0.7.1cdh3u4 # 建表</description>
    </item>
    
    <item>
      <title>使用eclipse调试hive mapreduce</title>
      <link>https://fatkun.github.io/2012/10/debug-hive-mapreduce-with-eclipse.html</link>
      <pubDate>Sun, 21 Oct 2012 12:12:35 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2012/10/debug-hive-mapreduce-with-eclipse.html</guid>
      <description>我们知道Hive经过一些转换后，提交job到hadoop，一般我们只能debug到submitJob这里，而不知道后面那些mapper到底是</description>
    </item>
    
    <item>
      <title>Hive查询用到的语句记录</title>
      <link>https://fatkun.github.io/2012/07/hive-query.html</link>
      <pubDate>Thu, 05 Jul 2012 09:03:59 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2012/07/hive-query.html</guid>
      <description>子查询 子查询需要一个别名 SELECT * FROM (SELECT A,B FROM atable) alaisName group by 这样的语句会报错，提示a不在group by里面 select a,sum(b) from atable group by b hive Expression Not In Group By Key via:来源 解决方法是</description>
    </item>
    
    <item>
      <title>Hive Select * 替换回列字段</title>
      <link>https://fatkun.github.io/2012/06/hive-select-star.html</link>
      <pubDate>Sun, 03 Jun 2012 16:11:42 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2012/06/hive-select-star.html</guid>
      <description>Hive中会把TOK_ALLCOLREF替换成各个列名称，来看看代码中是如何做到的。 我以TOK_ALLCOLREF入手看代码，执行顺序不是这</description>
    </item>
    
    <item>
      <title>格式化Hive语法树(python)</title>
      <link>https://fatkun.github.io/2012/05/format-hive-astnode.html</link>
      <pubDate>Sat, 19 May 2012 17:19:02 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2012/05/format-hive-astnode.html</guid>
      <description>为了容易看一点，把用explain得到的语法树加上一些缩进. 该代码只是简单的加上缩进. 效果 这是查询explain select key from kv mykv join test mytest on (mykv.key == myt</description>
    </item>
    
    <item>
      <title>eclipse上单步调试Hive</title>
      <link>https://fatkun.github.io/2012/04/eclipse-debug-hive.html</link>
      <pubDate>Sat, 14 Apr 2012 10:06:16 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2012/04/eclipse-debug-hive.html</guid>
      <description>在百度找到这篇文章：在Windows eclipse上单步调试Hive教程 可是我死活搞不定在windows安装hadoop和hive，cgyw</description>
    </item>
    
    <item>
      <title>Hive为什么会创建DELETEME表</title>
      <link>https://fatkun.github.io/2012/04/hive-deleteme-table.html</link>
      <pubDate>Tue, 10 Apr 2012 16:16:45 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2012/04/hive-deleteme-table.html</guid>
      <description>在Hive中会去取schme name和catalog（暂时不知道这个东西有什么用） 是第三方的库datanucleus在操作， 可以看到它创建D</description>
    </item>
    
    <item>
      <title>Hive MetaStore建表与修改表分析</title>
      <link>https://fatkun.github.io/2012/04/hive-metastore-create-table-and-alter-table.html</link>
      <pubDate>Tue, 10 Apr 2012 15:57:54 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2012/04/hive-metastore-create-table-and-alter-table.html</guid>
      <description>问题 使用Hive MetaStore（这里指的是通过thrift连接hiveserver） Create table 和 Alter table的时候遇到一个问题 建表时指定的lo</description>
    </item>
    
  </channel>
</rss>