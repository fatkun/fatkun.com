<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>hdfs on Fatkun&#39;s Blog</title>
    <link>https://fatkun.github.io/tags/hdfs/</link>
    <description>Recent content in hdfs on Fatkun&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 15 Jun 2018 03:35:54 +0000</lastBuildDate>
    
	<atom:link href="https://fatkun.github.io/tags/hdfs/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>hdfs acl 授权</title>
      <link>https://fatkun.github.io/2018/06/hdfs-acl-%E6%8E%88%E6%9D%83.html</link>
      <pubDate>Fri, 15 Jun 2018 03:35:54 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2018/06/hdfs-acl-%E6%8E%88%E6%9D%83.html</guid>
      <description>hdfs dfs -setfacl -m default:user:user1111:rwx /tmp/xxx hdfs dfs -setfacl -m user:user1111:rwx /tmp/xxx</description>
    </item>
    
    <item>
      <title>HDFS文件的健康检查</title>
      <link>https://fatkun.github.io/2017/07/hdfs-health-check.html</link>
      <pubDate>Sun, 16 Jul 2017 13:35:45 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2017/07/hdfs-health-check.html</guid>
      <description>文章来源：HDFS DataNode Scanners and Disk Checker Explained 以下只简单翻译部分文字，详情看英文原文。 简单的概念 一个文件包含多个block，一个block有一个或多个副本。</description>
    </item>
    
    <item>
      <title>hdfs磁盘检查相关文章</title>
      <link>https://fatkun.github.io/2017/07/hdfs%E7%A3%81%E7%9B%98%E6%A3%80%E6%9F%A5%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0.html</link>
      <pubDate>Sun, 16 Jul 2017 02:23:20 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2017/07/hdfs%E7%A3%81%E7%9B%98%E6%A3%80%E6%9F%A5%E7%9B%B8%E5%85%B3%E6%96%87%E7%AB%A0.html</guid>
      <description>DataNode启动优化改进：磁盘检测并行化 https://issues.apache.org/jira/browse/HDFS-8845 检查时不遍历所有子目录 https://issues.apache.org/jira/browse/HDFS-8850 VolumeScanner可能会抛nullpoint exception https://issues.apache.org/jira/browse/HDFS-7916 汇报坏块给st</description>
    </item>
    
    <item>
      <title>HDFS-6962 hdfs acl mask继承无效</title>
      <link>https://fatkun.github.io/2016/11/hdfs-6962-hdfs-acl-mask%E7%BB%A7%E6%89%BF%E6%97%A0%E6%95%88.html</link>
      <pubDate>Mon, 21 Nov 2016 10:50:03 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2016/11/hdfs-6962-hdfs-acl-mask%E7%BB%A7%E6%89%BF%E6%97%A0%E6%95%88.html</guid>
      <description>ACL inheritance conflicts with umaskmode https://issues.apache.org/jira/browse/HDFS-6962</description>
    </item>
    
    <item>
      <title>parquet编码定义</title>
      <link>https://fatkun.github.io/2016/11/parquet-encoding-definitions.html</link>
      <pubDate>Sun, 13 Nov 2016 12:29:49 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2016/11/parquet-encoding-definitions.html</guid>
      <description>主要是翻译https://github.com/Parquet/parquet-format/blob/master/Encodings.m</description>
    </item>
    
    <item>
      <title>hadoop组映射从配置文件读取</title>
      <link>https://fatkun.github.io/2016/07/hadoop-group-mapping-from-file.html</link>
      <pubDate>Sun, 31 Jul 2016 10:41:41 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2016/07/hadoop-group-mapping-from-file.html</guid>
      <description>hadoop实现类似linux系统的文件权限，需要知道某个用户是属于哪个组。系统默认是使用ShellBasedUnixGroupsMappi</description>
    </item>
    
    <item>
      <title>hadoop磁盘写入选择策略</title>
      <link>https://fatkun.github.io/2016/07/hadoop-volume-choosing-policy.html</link>
      <pubDate>Thu, 14 Jul 2016 10:27:36 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2016/07/hadoop-volume-choosing-policy.html</guid>
      <description>hadoop写入时，默认磁盘选择是轮询的方式。可以改用按空间大小来分配，避免某个磁盘特别满。 参数 ：dfs.datanode.fsdatase</description>
    </item>
    
    <item>
      <title>[HADOOP-11238]hdfs namenode getGroups延迟</title>
      <link>https://fatkun.github.io/2016/05/hadoop-11238.html</link>
      <pubDate>Sun, 15 May 2016 02:29:06 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2016/05/hadoop-11238.html</guid>
      <description>在namenode日志看到如下错误 2016-05-11 01:00:26,360 WARN org.apache.hadoop.security.Groups: Potential performance problem: getGroups(user=xxx) took 5046 milliseconds 这个方法是hadoop为了获取某个用户是哪个组。 分析补丁 补丁：https://iss</description>
    </item>
    
    <item>
      <title>DataNode启动流程源码分析</title>
      <link>https://fatkun.github.io/2016/05/datanode-start.html</link>
      <pubDate>Mon, 02 May 2016 09:28:42 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2016/05/datanode-start.html</guid>
      <description>背景 最近打算要重启DataNode，之前有试过重启过程中导致业务任务失败的情况。所以想了解DataNode什么时候才算启动完成，以及能否检测</description>
    </item>
    
    <item>
      <title>HDFS-8824 平衡数据的时候不移动小文件</title>
      <link>https://fatkun.github.io/2016/05/hdfs-8824.html</link>
      <pubDate>Sun, 01 May 2016 02:08:22 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2016/05/hdfs-8824.html</guid>
      <description>Do not use small blocks for balancing the cluster https://issues.apache.org/jira/browse/HDFS-8824 Allow Balancer to run faster https://issues.apache.org/jira/browse/HDFS-8818 平衡设置的文章：https://community.hortonworks.com/articles/438</description>
    </item>
    
    <item>
      <title>hdfs complete file 超时</title>
      <link>https://fatkun.github.io/2016/04/hdfs-complete-file-timeout.html</link>
      <pubDate>Mon, 25 Apr 2016 02:48:00 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2016/04/hdfs-complete-file-timeout.html</guid>
      <description>修改一下超时次数，具体代码在 DFSOutputStream.java private void completeFile(ExtendedBlock last) throws IOException { long localstart = Time.now(); long localTimeout = 400; boolean fileComplete = false; int retries = dfsClient.getConf().nBlockWriteLocateFollowingRetry; while (!fileComplete) { fileComplete = dfsClient.namenode.complete(src, dfsClient.clientName, last, fileId); if (!fileComplete) { final int hdfsTimeout = dfsClient.getHdfsTimeout(); if (!dfsClient.clientRunning &amp;brvbar;&amp;brvbar; (hdfsTimeout &amp;gt; 0 &amp;&amp; localstart + hdfsTimeout &amp;lt; Time.now())) { String msg</description>
    </item>
    
    <item>
      <title>hdfs启动相关文章</title>
      <link>https://fatkun.github.io/2016/04/hdfs-start.html</link>
      <pubDate>Sun, 24 Apr 2016 08:13:38 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2016/04/hdfs-start.html</guid>
      <description>记一次DataNode慢启动问题 ：启动过程中，datanode为了获取used size，如果超过时间，可能会执行DU。</description>
    </item>
    
    <item>
      <title>hdfs exceeds the limit of concurrent xcievers</title>
      <link>https://fatkun.github.io/2015/11/hdfs-exceeds-the-limit-of-concurrent-xcievers.html</link>
      <pubDate>Mon, 23 Nov 2015 11:53:49 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2015/11/hdfs-exceeds-the-limit-of-concurrent-xcievers.html</guid>
      <description>版本: hadoop cdh5.4 datanode jstack，很多这样的线程 &#34;DataXceiver for client unix:/var/run/hdfs-sockets/dn [Waiting for operation #1]&#34; daemon prio=10 tid=0x00007ffc42de9000 nid=0x68f8 waiting on condition [0x00007ffacbd1d000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &amp;lt;0x00000007a5d3d568&amp;gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043) at org.apache.hadoop.net.unix.DomainSocketWatcher.add(DomainSocketWatcher.java:316) at org.apache.hadoop.hdfs.server.datanode.ShortCircuitRegistry.createNewMemorySegment(ShortCircuitRegistry.java:322) at org.apache.hadoop.hdfs.server.datanode.DataXceiver.requestShortCircuitShm(DataXceiver.java:418) at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opRequestShortCircuitShm(Receiver.java:214) at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:95) at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:241) at java.lang.Thread.run(Thread.java:745) 相关</description>
    </item>
    
    <item>
      <title>Mismatched address stored in ZK for NameNode</title>
      <link>https://fatkun.github.io/2015/10/mismatched-address-stored-in-zk-for-namenode.html</link>
      <pubDate>Wed, 28 Oct 2015 08:28:52 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2015/10/mismatched-address-stored-in-zk-for-namenode.html</guid>
      <description>我在namenode配置dfs.namenode.servicerpc-address端口后，Failover Controller 报错 java.lang.RuntimeException: Mismatched address stored in ZK for NameNode at kpixxx/xx.xx.xx.xx:88 解决</description>
    </item>
    
    <item>
      <title>namenode standby checkponit时间过长导致的问题</title>
      <link>https://fatkun.github.io/2015/05/namenode-standby-checkponit.html</link>
      <pubDate>Sun, 03 May 2015 13:30:28 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2015/05/namenode-standby-checkponit.html</guid>
      <description>我们当前使用的版本是cdh-4.2.1，standby namenode默认每小时生成一个editlog文件，由于操作很多，这个保存时间超过了</description>
    </item>
    
    <item>
      <title>hdfs httpfs与webhdfs的简单使用</title>
      <link>https://fatkun.github.io/2014/11/httpfs-and-webhdfs.html</link>
      <pubDate>Sun, 02 Nov 2014 08:46:33 +0000</pubDate>
      
      <guid>https://fatkun.github.io/2014/11/httpfs-and-webhdfs.html</guid>
      <description>HttpFS和WebHDFS 通过http协议操作hdfs有两个组件，httpfs和webhdfs，我一开始还以为这两个是同一个东西，其实不是</description>
    </item>
    
  </channel>
</rss>